{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6a86c3",
   "metadata": {},
   "source": [
    "# **Linear Models (Part 2)**\n",
    "\n",
    "Outlier Robust Regression\n",
    "\n",
    "Noah Rubin\n",
    "\n",
    "June 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c3495b",
   "metadata": {},
   "source": [
    "# Huber Regressor \n",
    "\n",
    "Intro:\n",
    "* The [Huber Regressor](https://towardsdatascience.com/regression-in-the-face-of-messy-outliers-try-huber-regressor-3a54ddc12516) model is designed to try address the problem of outliers that may exist in the dataset and thus falls under a family of models known as robust regression models\n",
    "* Sometimes it can be used as a good alternative to OLS as OLS tends to pull the fit towards each datapoint, hence outliers can really distort the fit, catalysing inaccurate predictions\n",
    "* Algorithm was invented by Peter Jost Huber in 1964 though subtle adjustments have been made over time\n",
    "* As such, the sklearn documentation mentions that its implementation is based off [this academic paper](https://artowen.su.domains/reports/hhu.pdf), published in 2006.\n",
    "\n",
    "In the sklearn implementation, the Huber loss function applies a transformation to the error depending on it's value, in which we intend to minimise the quantity\n",
    "\n",
    "$$J = \\sum_{i=1}^n \\big(\\sigma + H_\\epsilon\\big(\\frac{y_i - \\hat{y}_i}{\\sigma} \\big) \\big) + \\alpha||\\vec{\\beta}||^2$$\n",
    "\n",
    "whereby $y_i - \\hat{y}_i$. The huber regressor finds an optimal value for $\\sigma \\in (0, \\infty)$ as well as finding the components of the $\\vec{\\beta}$ vector based on the minimisation of this loss function. The regularisation term $\\alpha||\\vec{\\beta}||^2$ acts as the $L_2$ shrinkage penalty and the function $H$ is piecewise and takes in scalar input $z$ such that\n",
    "\n",
    "$$H_\\epsilon(z) = \\begin{cases}\n",
    "z{^2} & \\text{if } |z| < \\epsilon,\\\\\n",
    "2\\epsilon|z| - \\epsilon^2  & \\text{if } |z| \\geq \\epsilon\\\\\n",
    "\\end{cases}$$\n",
    "\n",
    "---\n",
    "\n",
    "According to Scikit-Learn documentation, this minimisation process \"makes sure that the loss function is not heavily influenced by the outliers while not completely ignoring their effect.\" One other tip was to set the threshold parameter $\\epsilon$ to 1.35 \"to achieve 95% statistical efficiency\".\n",
    "\n",
    "Resources\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.HuberRegressor.html\n",
    "* https://scikit-learn.org/stable/modules/linear_model.html#huber-regression\n",
    "* https://artowen.su.domains/reports/hhu.pdf\n",
    "* https://cvxr.rbind.io/cvxr_examples/cvxr_huber-regression/\n",
    "* https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3\n",
    "* https://en.wikipedia.org/wiki/Robust_regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aa39ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "# Personal display settings\n",
    "#===========================\n",
    "\n",
    "# Suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Get dataset values showing to 5dp\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# For clear plots with a nice background\n",
    "plt.style.use('seaborn-whitegrid') \n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# python files\n",
    "import data_prep\n",
    "import helper_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019635b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('identity',\n",
       "                                                                   FunctionTransformer())]),\n",
       "                                                  ['GDP_cap']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder(drop='first'))]),\n",
       "                                                  ['Status'])])),\n",
       "                ('imputation', KNNImputer()), ('ss', StandardScaler()),\n",
       "                ('model', HuberRegressor())])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huber_pipeline = data_prep.create_pipeline(HuberRegressor())\n",
    "huber_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21be344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter grid used in every model\n",
    "param_grid = {\n",
    "    'imputation__n_neighbors': np.arange(3, 16, 2), \n",
    "    'imputation__weights': ['uniform', 'distance'],\n",
    "    'model__alpha': np.linspace(0.01, 3, 10)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
